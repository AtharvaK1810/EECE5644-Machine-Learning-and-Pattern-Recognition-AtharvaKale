
"""Assignment 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10B8TZryXGXH4Q9-EPRfCWyNkwutrw19T
"""


import os, math, time, numpy as np
import matplotlib.pyplot as plt

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader
except Exception:
    !pip -q install torch --extra-index-url https://download.pytorch.org/whl/cpu
    import torch
    import torch.nn as nn
    from torch.utils.data import TensorDataset, DataLoader

from sklearn.decomposition import PCA
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
from sklearn.mixture import GaussianMixture


NAME  = "Atharva Prashant Kale"
NUID  = "002442878"
EMAIL = "kale.ath@northeastern.edu"

OUT_DIR = "a3_outputs"
FIG_DIR = os.path.join(OUT_DIR, "figs")
RES_DIR = os.path.join(OUT_DIR, "results")
os.makedirs(FIG_DIR, exist_ok=True)
os.makedirs(RES_DIR, exist_ok=True)

def add_signature_py(ax_or_fig, name=NAME, nuid=NUID, email=EMAIL):
    """Stamp a light signature on the current figure (bottom-right)."""
    ax = ax_or_fig if hasattr(ax_or_fig, "text") else plt.gca()
    txt = f"{name} | NUID: {nuid} | {email}"
    ax.text(0.99, -0.12, txt, transform=ax.transAxes, ha="right", va="top", fontsize=8, alpha=0.7)

def savefig(path):
    plt.tight_layout()
    plt.savefig(path, bbox_inches="tight")
    plt.close()

np.random.seed(5644)
torch.manual_seed(5644)


def log_gaussian_pdf(X, mean, cov):
    """Row-wise log N(x|mean,cov) for X: NxD."""
    Xc = X - mean
    L = np.linalg.cholesky(cov + 1e-8 * np.eye(cov.shape[0]))
    sol = np.linalg.solve(L, Xc.T)
    quad = (sol * sol).sum(axis=0)
    const = X.shape[1] * np.log(2*np.pi) + 2*np.log(np.diag(L)).sum()
    return -0.5 * (const + quad)

def sample_4class_gauss_3d(N, means, covs, pri):
    K = means.shape[0]
    y = np.random.choice(K, size=N, p=pri)
    X = np.zeros((N, 3))
    for k in range(K):
        idx = (y == k)
        nk = idx.sum()
        if nk > 0:
            X[idx] = np.random.multivariate_normal(means[k], covs[k], nk)
    return X, y + 1 

def q1_compute_oracle_error(means, covs, pri, M=200000):
    K = means.shape[0]; D = means.shape[1]
    X = np.zeros((M, D)); y = np.zeros(M, dtype=int)
    cum = np.cumsum(pri)
    u = np.random.rand(M)
    for k in range(K):
        sel = (u <= cum[k]) & (y == 0)
        n = sel.sum()
        if n > 0:
            X[sel] = np.random.multivariate_normal(means[k], covs[k], n)
            y[sel] = k + 1
    logp = np.zeros((M, K))
    for k in range(K):
        logp[:, k] = log_gaussian_pdf(X, means[k], covs[k]) + np.log(pri[k])
    yhat = 1 + np.argmax(logp, axis=1)
    return np.mean(yhat != y)

class OneHiddenMLP(nn.Module):
    def __init__(self, d_in, d_hid, d_out):
        super().__init__()
        self.fc1 = nn.Linear(d_in, d_hid)
        self.act = nn.ELU()  
        self.fc2 = nn.Linear(d_hid, d_out)
    def forward(self, x):
        return self.fc2(self.act(self.fc1(x)))

def train_mlp_torch(Xtr, ytr, Xva, yva, P, epochs=80, batch=64, lr=0.05, weight_decay=1e-4):
    device = torch.device("cpu")
    model = OneHiddenMLP(Xtr.shape[1], P, 4).to(device)
    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)
    ds = TensorDataset(torch.tensor(Xtr, dtype=torch.float32), torch.tensor(ytr-1, dtype=torch.long))
    dl = DataLoader(ds, batch_size=batch, shuffle=True)
    Xv = torch.tensor(Xva, dtype=torch.float32)
    yv = torch.tensor(yva-1, dtype=torch.long)

    best_nll = float("inf")
    best_state = None

    for ep in range(epochs):
   
        for g in opt.param_groups:
            g['lr'] = lr * (0.98 ** ep)
        model.train()
        for xb, yb in dl:
            opt.zero_grad()
            logits = model(xb)
            loss = nn.CrossEntropyLoss()(logits, yb)
            loss.backward()
            opt.step()

        model.eval()
        with torch.no_grad():
            logits = model(Xv)
            nll = nn.CrossEntropyLoss()(logits, yv).item()
        if nll < best_nll:
            best_nll = nll
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}


    if best_state is not None:
        model.load_state_dict(best_state)
    return model

def eval_error(model, X, y):
    with torch.no_grad():
        logits = model(torch.tensor(X, dtype=torch.float32))
        pred = torch.argmax(logits, dim=1).cpu().numpy() + 1
    return np.mean(pred != y), pred

def q1_run():
    print("[Q1] Training and evaluating 4-class MLP classifier...")

    means = np.array([
        [0, 0, 0],
        [3, 0, 0],
        [0, 3, 0],
        [3, 3, 2],
    ], dtype=float)
    covs = np.stack([0.8 * np.eye(3)] * 4, axis=0)
    pri  = np.array([0.25, 0.25, 0.25, 0.25])

    Ns = [100, 500, 1000, 5000, 10000]
    Pgrid = [4, 8, 16, 32, 64]
    kfolds = 10
    restarts = 5
    epochs = 80
    batch = 64
    lr = 0.05
    weight_decay = 1e-4


    oracle_err = q1_compute_oracle_error(means, covs, pri, M=200000)

    results = []  

    for N in Ns:
       
        X, y = sample_4class_gauss_3d(N, means, covs, pri)
        idx = np.random.permutation(N)
        n_tr = int(0.6 * N); n_va = int(0.2 * N)
        tr_idx = idx[:n_tr]
        va_idx = idx[n_tr:n_tr+n_va]
        te_idx = idx[n_tr+n_va:]

        Xtr = X[tr_idx]; ytr = y[tr_idx]
        Xva = X[va_idx]; yva = y[va_idx]
        Xte = X[te_idx]; yte = y[te_idx]

    
        mu = Xtr.mean(axis=0); sg = Xtr.std(axis=0); sg[sg < 1e-8] = 1.0
        Xtr = (Xtr - mu) / sg
        Xva = (Xva - mu) / sg
        Xte = (Xte - mu) / sg

    
        kf = KFold(n_splits=kfolds, shuffle=True, random_state=123)
        cv_loss_per_P = []
        for P in Pgrid:
            fold_losses = []
            for tr_mask, va_mask in kf.split(Xtr):
                XcvTr, XcvVa = Xtr[tr_mask], Xtr[va_mask]
                ycvTr, ycvVa = ytr[tr_mask], ytr[va_mask]
                best_nll = float("inf")
                for r in range(restarts):
                    model = train_mlp_torch(XcvTr, ycvTr, XcvVa, ycvVa,
                                            P, epochs=epochs, batch=batch, lr=lr, weight_decay=weight_decay)
                 
                    with torch.no_grad():
                        logits = model(torch.tensor(XcvVa, dtype=torch.float32))
                        nll = nn.CrossEntropyLoss()(logits, torch.tensor(ycvVa-1)).item()
                    best_nll = min(best_nll, nll)
                fold_losses.append(best_nll)
            cv_loss_per_P.append(np.mean(fold_losses))

        P_star = Pgrid[int(np.argmin(cv_loss_per_P))]

        
        Xtrva = np.vstack([Xtr, Xva]); ytrva = np.hstack([ytr, yva])
        best_te = float("inf"); best_pred = None; best_model = None
        for r in range(restarts):
            model = train_mlp_torch(Xtrva, ytrva, Xte, yte, P_star,
                                    epochs=epochs, batch=batch, lr=lr, weight_decay=weight_decay)
            te_err, pred = eval_error(model, Xte, yte)
            if te_err < best_te:
                best_te = te_err; best_pred = pred; best_model = model

        results.append([N, P_star, best_te, oracle_err])
        print(f"[N={N}] P*={P_star} | Test P(error)={best_te:.4f} | Oracle={oracle_err:.4f}")

     
        X_all = np.vstack([Xtrva, Xte]); y_all = np.hstack([ytrva, yte])
        pca = PCA(n_components=2).fit(X_all)
        Xp = pca.transform(X_all)
        plt.figure()
   
        for cls in [1,2,3,4]:
            m = (y_all == cls)
            plt.scatter(Xp[m,0], Xp[m,1], s=10, label=f"Class {cls}")
        plt.title("Q1: PCA(3D→2D) scatter")
        plt.xlabel("PC1"); plt.ylabel("PC2"); plt.grid(True); plt.axis("equal")
        plt.legend(loc="best", fontsize=8)
        add_signature_py(plt.gca())
        savefig(os.path.join(FIG_DIR, "Q1_pca_scatter.pdf"))

     
        C = confusion_matrix(yte, best_pred, labels=[1,2,3,4])
        plt.figure()
        plt.imshow(C, aspect="equal")
        plt.colorbar()
        plt.title(f"Q1: Confusion (Test), N={N}, P*={P_star}")
        plt.xlabel("Predicted"); plt.ylabel("True")
        plt.xticks([0,1,2,3], [1,2,3,4]); plt.yticks([0,1,2,3], [1,2,3,4])
        add_signature_py(plt.gca())
        savefig(os.path.join(FIG_DIR, f"Q1_confusion_mlp_test_N{N}.pdf"))


    csv_path = os.path.join(RES_DIR, "Q1_mlp_results.csv")
    with open(csv_path, "w") as f:
        f.write("N,Pstar,test_error,oracle_error\n")
        for row in results:
            f.write(f"{row[0]},{row[1]},{row[2]:.6f},{row[3]:.6f}\n")

    
    arr = np.array(results)
    Ns_out, Errs = arr[:,0], arr[:,2]
    plt.figure()
    plt.semilogx(Ns_out, Errs, "-o", linewidth=2)
    plt.axhline(y=oracle_err, linestyle="--")
    plt.title("Q1: Test P(error) vs N (semilog-x)")
    plt.xlabel("N (log scale)"); plt.ylabel("Test P(error)")
    plt.grid(True)
    add_signature_py(plt.gca())
    savefig(os.path.join(FIG_DIR, "Q1_mlp_test_error.pdf"))


def sample_true_mix(N):
   
    means = np.array([[0.0, 0.0],
                      [0.5, 0.3],    
                      [3.0, 0.0],
                      [3.0, 3.0]])
    cov = 0.6 * np.eye(2)
    covs = np.stack([cov]*4, axis=0)
    pri = np.array([0.25, 0.25, 0.25, 0.25])

    z = np.random.choice(4, size=N, p=pri)
    X = np.zeros((N,2))
    for k in range(4):
        idx = (z == k)
        nk = idx.sum()
        if nk > 0:
            X[idx] = np.random.multivariate_normal(means[k], covs[k], nk)
    return X, z

def cv_mean_loglike(X, K, nfolds=10, max_iter=600, n_init=5, reg_covar=1e-3):
    kf = KFold(n_splits=nfolds, shuffle=True, random_state=123)
    lls = []
    for tr, te in kf.split(X):
        Xtr, Xte = X[tr], X[te]
        try:
            gm = GaussianMixture(n_components=K,
                                 covariance_type="full",
                                 max_iter=max_iter,
                                 n_init=n_init,
                                 reg_covar=reg_covar,
                                 random_state=123)
            gm.fit(Xtr)
            lls.append(gm.score(Xte))  
        except Exception:
            lls.append(-np.inf)
    return float(np.mean(lls))

def q2_run():
    print("[Q2] GMM model order selection via 10-fold CV (Python)")
    Ns = [10, 100, 1000]
    K_grid = list(range(1, 11))
    kfolds = 10
    repeats = 100


    X_demo, _ = sample_true_mix(1000)
    plt.figure()
    plt.scatter(X_demo[:,0], X_demo[:,1], s=6)
    plt.title("Q2: Example draw (overlapping true mixture)")
    plt.xlabel("x1"); plt.ylabel("x2"); plt.axis("equal"); plt.grid(True)
    add_signature_py(plt.gca())
    savefig(os.path.join(FIG_DIR, "Q2_example_fit_py.png"))

    sel_counts = np.zeros((len(Ns), len(K_grid)), dtype=int)

    t0 = time.time()
    print("=== Q2 GMM model order selection (Python full version) ===")
    for r in range(1, repeats+1):
        print(f"[Repeat {r}/{repeats}]")
        for iN, N in enumerate(Ns):
            X, _ = sample_true_mix(N)
            meanLLs = []
            for K in K_grid:
                mll = cv_mean_loglike(X, K, nfolds=kfolds, max_iter=600, n_init=5, reg_covar=1e-3)
                meanLLs.append(mll)
            best_idx = int(np.argmax(meanLLs))
            sel_counts[iN, best_idx] += 1
            print(f"  N={N:<5d} | best K={K_grid[best_idx]} | meanLL={meanLLs[best_idx]:.3f}")
    print(f"Q2 complete in {time.time()-t0:.1f}s")

    rates = sel_counts / repeats

    csv_path = os.path.join(RES_DIR, "Q2_gmm_selection_rates_py.csv")
    with open(csv_path, "w") as f:
        f.write("N,K,rate\n")
        for iN, N in enumerate(Ns):
            for jK, K in enumerate(K_grid):
                f.write(f"{N},{K},{rates[iN,jK]:.6f}\n")

 
    plt.figure()
    plt.imshow(rates, aspect="auto", origin="upper",
               extent=[K_grid[0], K_grid[-1], Ns[-1]+0.5, Ns[0]-0.5])
    plt.colorbar()
    plt.xlabel("K"); plt.ylabel("N")
    plt.title("Q2: CV selection rate (Python, 10-fold, 100 reps)")
    add_signature_py(plt.gca())
    savefig(os.path.join(FIG_DIR, "Q2_gmm_selection_heatmap_py.png"))

   
    for iN, N in enumerate(Ns):
        plt.figure()
        plt.bar(K_grid, rates[iN])
        plt.ylim(0,1); plt.grid(True, axis="y", alpha=0.4)
        plt.xlabel("K"); plt.ylabel("Selection rate")
        plt.title(f"Q2: Selection counts (N={N}; reps={repeats})")
        add_signature_py(plt.gca())
        savefig(os.path.join(FIG_DIR, f"Q2_selection_bars_N{N}_py.png"))


print("=== EECE5644 Assignment 3: RUN ALL (Q1–Q2) ===\n")
q1_run()
print("\nQ1 finished. Figures and CSV saved.\n")
q2_run()
print("\nAll done. Outputs saved under:", OUT_DIR)


print("\nFiles created:")
for root, _, files in os.walk(OUT_DIR):
    for fn in files:
        print(os.path.join(root, fn))
